"""
LangGraph ê¸°ë°˜ í”„ë¡œì íŠ¸ ì¸ì› ì¶”ì²œ ì—ì´ì „íŠ¸
=========================================

ì´ ëª¨ë“ˆì€ LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”í˜• AI ì—ì´ì „íŠ¸ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ í”„ë¡œì íŠ¸ ìš”ì²­ì„ ë¶„ì„í•˜ê³  ì í•©í•œ ì¸ì›ì„ ì¶”ì²œí•˜ëŠ” ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ì‚¬ìš©ì ìš”ì²­ ë¶„ì„ ë° êµ¬ì¡°í™”
- ì°¸ì—¬ì íƒìƒ‰ ë° ì í•©ë„ ê³„ì‚°
- ì¶”ì²œ ê²°ê³¼ ìƒì„± ë° í¬ë§·íŒ…
- LangGraph ì›Œí¬í”Œë¡œìš° ê´€ë¦¬

ì‘ì„±ì: AI Assistant
ë²„ì „: 1.0.0
"""

from typing import Dict, List, Any, TypedDict, Annotated
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeoutError
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from ..core.data_loader import ProjectDataLoader
from ..core.similarity_analyzer import SimilarityAnalyzer
from ..core.config import OPENAI_API_KEY

class AgentState(TypedDict):
    """
    LangGraph ì—ì´ì „íŠ¸ì˜ ìƒíƒœë¥¼ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬í•˜ëŠ” ëª¨ë“  ë°ì´í„°ì˜ êµ¬ì¡°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
    """
    messages: Annotated[List, add_messages]  # ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    user_request: str                        # ì‚¬ìš©ì ìš”ì²­ ë‚´ìš©
    recommendations: List[Dict[str, Any]]    # ì¶”ì²œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    analysis_complete: bool                  # ë¶„ì„ ì™„ë£Œ ì—¬ë¶€

class ProjectRecommendationAgent:
    """
    LangGraph ê¸°ë°˜ í”„ë¡œì íŠ¸ ì¸ì› ì¶”ì²œ ì—ì´ì „íŠ¸
    
    ì´ í´ë˜ìŠ¤ëŠ” LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”í˜• AI ì—ì´ì „íŠ¸ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ í”„ë¡œì íŠ¸ ìš”ì²­ì„ ë°›ì•„ì„œ ì í•©í•œ ì¸ì›ì„ ì¶”ì²œí•˜ëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    
    ì›Œí¬í”Œë¡œìš°:
    1. ì‚¬ìš©ì ìš”ì²­ ë¶„ì„
    2. ì í•©í•œ ì°¸ì—¬ì íƒìƒ‰
    3. ì¶”ì²œ ê²°ê³¼ ìƒì„±
    4. ìµœì¢… ì‘ë‹µ í¬ë§·íŒ…
    """
    
    def __init__(self):
        """
        ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        
        í•„ìš”í•œ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì´ˆê¸°í™”í•˜ê³  LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
        """
        # OpenAI GPT ëª¨ë¸ ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model="gpt-3.5-turbo",  # ì‚¬ìš©í•  GPT ëª¨ë¸
            temperature=0.1,        # ì°½ì˜ì„± ìˆ˜ì¤€ (ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„± ë†’ìŒ)
            api_key=OPENAI_API_KEY
        )
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.data_loader = ProjectDataLoader()
        self.similarity_analyzer = SimilarityAnalyzer()
        
        # LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """
        LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•˜ëŠ” ë©”ì„œë“œ
        
        Returns:
            StateGraph: êµ¬ì„±ëœ LangGraph ì›Œí¬í”Œë¡œìš°
        """
        workflow = StateGraph(AgentState)
        
        # ì›Œí¬í”Œë¡œìš° ë…¸ë“œ ì¶”ê°€
        workflow.add_node("analyze_request", self._analyze_request)
        workflow.add_node("find_suitable_participants", self._find_suitable_participants)
        workflow.add_node("generate_recommendations", self._generate_recommendations)
        workflow.add_node("format_response", self._format_response)
        
        # ì›Œí¬í”Œë¡œìš° ì—£ì§€ ì¶”ê°€ (ìˆœì°¨ì  ì‹¤í–‰)
        workflow.set_entry_point("analyze_request")
        workflow.add_edge("analyze_request", "find_suitable_participants")
        workflow.add_edge("find_suitable_participants", "generate_recommendations")
        workflow.add_edge("generate_recommendations", "format_response")
        workflow.add_edge("format_response", END)
        
        return workflow.compile()
    
    def _analyze_request(self, state: AgentState) -> AgentState:
        """
        ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ëŠ” ë…¸ë“œ
        
        ì‚¬ìš©ìì˜ í”„ë¡œì íŠ¸ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            state (AgentState): í˜„ì¬ ì—ì´ì „íŠ¸ ìƒíƒœ
            
        Returns:
            AgentState: ë¶„ì„ ê²°ê³¼ê°€ ì¶”ê°€ëœ ìƒíƒœ
        """
        messages = state["messages"]
        user_message = messages[-1].content if messages else ""
        
        # ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ì¶œ
        analysis_prompt = f"""
        ì‚¬ìš©ìì˜ í”„ë¡œì íŠ¸ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
        
        ì‚¬ìš©ì ìš”ì²­: {user_message}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
        1. í”„ë¡œì íŠ¸ ë¶„ì•¼/ë„ë©”ì¸
        2. ì£¼ìš” í‚¤ì›Œë“œ/íƒœê·¸
        3. í•„ìš”í•œ ì—­ëŸ‰/ê²½í—˜
        4. í”„ë¡œì íŠ¸ íŠ¹ì„± (ì‹ ê·œ/ê°œì„ /ì „ëµ ë“±)
        
        ë¶„ì„ ê²°ê³¼:
        """
        
        # GPTë¥¼ ì‚¬ìš©í•œ ìš”ì²­ ë¶„ì„
        response = self.llm.invoke([
            SystemMessage(content="ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ìš”ì²­ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
            HumanMessage(content=analysis_prompt)
        ])
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state["user_request"] = user_message
        state["messages"].append(response)
        
        return state
    
    def _find_suitable_participants(self, state: AgentState) -> AgentState:
        """
        ì í•©í•œ ì°¸ì—¬ìë¥¼ ì°¾ëŠ” ë…¸ë“œ
        
        ëª¨ë“  ì°¸ì—¬ìë¥¼ ëŒ€ìƒìœ¼ë¡œ ì í•©ë„ë¥¼ ê³„ì‚°í•˜ê³  ì„ê³„ê°’ ì´ìƒì¸ ì°¸ì—¬ìë“¤ì„ ì„ ë³„í•©ë‹ˆë‹¤.
        
        Args:
            state (AgentState): í˜„ì¬ ì—ì´ì „íŠ¸ ìƒíƒœ
            
        Returns:
            AgentState: ì„ ë³„ëœ ì°¸ì—¬ìë“¤ì´ ì¶”ê°€ëœ ìƒíƒœ
        """
        user_request = state["user_request"]
        all_participants = self.data_loader.get_all_participants()
        
        participant_scores = []
        
        # ëª¨ë“  ì°¸ì—¬ìì— ëŒ€í•´ ì í•©ë„ ê³„ì‚°
        for participant in all_participants:
            # ì°¸ì—¬ìì˜ í”„ë¡œì íŠ¸ë“¤ ê°€ì ¸ì˜¤ê¸°
            participant_projects = self.data_loader.get_projects_by_participant(participant)
            
            # ì í•©ë„ ê³„ì‚°
            suitability = self.similarity_analyzer.calculate_participant_suitability(
                user_request, participant, participant_projects
            )
            
            # ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ í¬í•¨ (FAISS ê¸°ë°˜ ì ìˆ˜ì— ë§ê²Œ ì¡°ì •)
            if suitability['total_score'] >= 0.01:  # ë§¤ìš° ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ í•„í„°ë§
                participant_scores.append(suitability)
        
        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        participant_scores.sort(key=lambda x: x['total_score'], reverse=True)
        
        # ìƒìœ„ 10ëª…ë§Œ ì„ íƒ
        state["recommendations"] = participant_scores[:10]
        return state
    
    def _generate_recommendations(self, state: AgentState) -> AgentState:
        """
        ì¶”ì²œ ê²°ê³¼ë¥¼ ìƒì„±í•˜ê³  ì •ë¦¬í•˜ëŠ” ë…¸ë“œ
        
        ì„ ë³„ëœ ì°¸ì—¬ìë“¤ì— ëŒ€í•œ ìƒì„¸í•œ ì¶”ì²œ ì •ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            state (AgentState): í˜„ì¬ ì—ì´ì „íŠ¸ ìƒíƒœ
            
        Returns:
            AgentState: ì •ë¦¬ëœ ì¶”ì²œ ê²°ê³¼ê°€ ì¶”ê°€ëœ ìƒíƒœ
        """
        recommendations = state["recommendations"]
        
        if not recommendations:
            state["messages"].append(
                HumanMessage(content="ìš”ì²­í•˜ì‹  í”„ë¡œì íŠ¸ì— ì í•©í•œ ì¸ì›ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            )
            return state
        
        # ìƒìœ„ 5ëª…ë§Œ ì„ íƒ
        top_recommendations = recommendations[:5]
        
        # ê° ì¶”ì²œì— ëŒ€í•œ ìƒì„¸ ë¶„ì„
        detailed_recommendations = []
        for rec in top_recommendations:
            detailed_rec = {
                'participant': rec['participant'],
                'total_score': rec['total_score'],
                'recent_score': rec['recent_score'],
                'project_count': rec['project_count'],
                'recent_project_count': rec['recent_project_count'],
                'reasons': rec['reasons'],
                'best_matches': rec['best_matches'][:2]  # ìƒìœ„ 2ê°œ í”„ë¡œì íŠ¸ë§Œ
            }
            detailed_recommendations.append(detailed_rec)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state["recommendations"] = detailed_recommendations
        state["analysis_complete"] = True
        
        return state
    
    def _format_response(self, state: AgentState) -> AgentState:
        """
        ìµœì¢… ì‘ë‹µì„ í¬ë§·íŒ…í•˜ëŠ” ë…¸ë“œ
        
        ì¶”ì²œ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
        
        Args:
            state (AgentState): í˜„ì¬ ì—ì´ì „íŠ¸ ìƒíƒœ
            
        Returns:
            AgentState: í¬ë§·íŒ…ëœ ì‘ë‹µì´ ì¶”ê°€ëœ ìƒíƒœ
        """
        recommendations = state["recommendations"]
        
        if not recommendations:
            response_text = "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  í”„ë¡œì íŠ¸ì— ì í•©í•œ ì¸ì›ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        else:
            response_text = "ğŸ¯ **í”„ë¡œì íŠ¸ ì¸ì› ì¶”ì²œ ê²°ê³¼**\n\n"
            response_text += f"ì´ {len(recommendations)}ëª…ì˜ ì í•©í•œ ì¸ì›ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.\n\n"
            
            for i, rec in enumerate(recommendations, 1):
                response_text += f"## ğŸ† {i}. {rec['participant']}\n"
                response_text += f"**ì í•©ë„ ì ìˆ˜**: {rec['total_score']:.2f} | "
                response_text += f"**ìµœê·¼ ê²½í—˜**: {rec['recent_score']:.2f} | "
                response_text += f"**ì´ í”„ë¡œì íŠ¸**: {rec['project_count']}ê°œ | "
                response_text += f"**ìµœê·¼ í”„ë¡œì íŠ¸**: {rec['recent_project_count']}ê°œ\n\n"
                
                response_text += "### ğŸ’¡ ìƒì„¸ ì¶”ì²œ ì´ìœ \n"
                for reason in rec['reasons']:
                    response_text += f"â€¢ {reason}\n"
                
                if rec['best_matches']:
                    response_text += "\n### ğŸ“‹ ê´€ë ¨ í”„ë¡œì íŠ¸ ê²½í—˜\n"
                    for j, match in enumerate(rec['best_matches'], 1):
                        project = match['project']
                        score = match['score']
                        response_text += f"**{j}. {project['í”„ë¡œì íŠ¸ëª…']}** (ë§¤ì¹­ë„: {score:.2f})\n"
                        response_text += f"   - ê¸°ê°„: {project['í”„ë¡œì íŠ¸ê¸°ê°„']}\n"
                        response_text += f"   - íƒœê·¸: {', '.join(project['í”„ë¡œì íŠ¸íƒœê·¸'])}\n"
                        response_text += f"   - ê°œìš”: {project['í”„ë¡œì íŠ¸ê°œìš”'][:100]}...\n\n"
                
                response_text += "---\n\n"
        
        # ìµœì¢… ì‘ë‹µì„ ìƒíƒœì— ì¶”ê°€
        state["messages"].append(HumanMessage(content=response_text))
        return state
    
    def process_request(self, user_input: str, timeout_sec: int = 600) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ ë©”ì„œë“œ
        
        ì´ ë©”ì„œë“œëŠ” ì‚¬ìš©ìì˜ í”„ë¡œì íŠ¸ ìš”ì²­ì„ ë°›ì•„ì„œ ì í•©í•œ ì¸ì›ì„ ì¶”ì²œí•˜ëŠ”
        ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            user_input (str): ì‚¬ìš©ìì˜ í”„ë¡œì íŠ¸ ìš”ì²­ ë‚´ìš©
            
        Returns:
            Dict[str, Any]: ì¶”ì²œ ê²°ê³¼ì™€ ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state = {
            "messages": [HumanMessage(content=user_input)],
            "user_request": "",
            "recommendations": [],
            "analysis_complete": False
        }
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (íƒ€ì„ì•„ì›ƒ ë³´í˜¸)
        def _run_workflow():
            return self.graph.invoke(initial_state)

        with ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(_run_workflow)
            try:
                result = future.result(timeout=timeout_sec)
                return {
                    "response": result["messages"][-1].content,
                    "recommendations": result.get("recommendations", [])
                }
            except FuturesTimeoutError:
                return {
                    "response": "â±ï¸ ì²˜ë¦¬ ì‹œê°„ì´ 10ë¶„ì„ ì´ˆê³¼í•˜ì—¬ ìš”ì²­ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤. ì…ë ¥ì„ ê°„ì†Œí™”í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                    "recommendations": []
                }

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
    agent = ProjectRecommendationAgent()
    
    # í…ŒìŠ¤íŠ¸ ìš”ì²­ ì²˜ë¦¬
    result = agent.process_request("AI ê¸°ë°˜ ê³ ê° ì„œë¹„ìŠ¤ ê°œì„  í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ë ¤ê³  í•©ë‹ˆë‹¤.")
    print(result["response"])

"""
ì°¸ì—¬ì ë¶„ì„ ëª¨ë“ˆ
================

ì°¸ì—¬ì ê´€ë ¨ ë¶„ì„ ë° í•„í„°ë§ ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ì°¸ì—¬ìë³„ í”„ë¡œì íŠ¸ ë§¤í•‘ ìƒì„±
- FAISS ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ì°¸ì—¬ì ì„ ë³„
- ì°¸ì—¬ì ì í•©ë„ ê³„ì‚° ë° ì •ë ¬

ì‘ì„±ì: AI Assistant
ë²„ì „: 1.0.0
"""

from typing import Dict, List, Any, Tuple
import os
from ..core.data_loader import ProjectDataLoader
from ..core.similarity_analyzer import SimilarityAnalyzer
from ..core.config import VECTOR_DB_DIR, VECTOR_COLLECTION_NAME


class ParticipantAnalyzer:
    """
    ì°¸ì—¬ì ë¶„ì„ ë° í•„í„°ë§ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” ì°¸ì—¬ì ê´€ë ¨ ëª¨ë“  ë¶„ì„ ë¡œì§ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, data_loader: ProjectDataLoader, similarity_analyzer: SimilarityAnalyzer):
        """
        ì°¸ì—¬ì ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            data_loader: í”„ë¡œì íŠ¸ ë°ì´í„° ë¡œë”
            similarity_analyzer: ìœ ì‚¬ë„ ë¶„ì„ê¸°
        """
        self.data_loader = data_loader
        self.similarity_analyzer = similarity_analyzer
    
    def find_suitable_participants(self, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        ì í•©í•œ ì°¸ì—¬ìë¥¼ ì°¾ëŠ” ë©”ì¸ ë©”ì„œë“œ (ìµœì í™”ëœ ë²„ì „)
        
        FAISS ê²€ìƒ‰ì„ í•œ ë²ˆë§Œ ìˆ˜í–‰í•˜ê³ , ë§¤ì¹­ë˜ëŠ” ì°¸ì—¬ìë§Œ ì„ ë³„í•˜ì—¬ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤.
        
        Args:
            analysis: ì‚¬ìš©ì ìš”ì²­ ë¶„ì„ ê²°ê³¼
            
        Returns:
            List[Dict[str, Any]]: ì„ ë³„ëœ ì°¸ì—¬ì ëª©ë¡
        """
        all_participants = self.data_loader.get_all_participants()
        
        print(f"ğŸ” ì´ {len(all_participants)}ëª…ì˜ ì°¸ì—¬ì ì¤‘ì—ì„œ ì í•©í•œ ì¸ì›ì„ ì°¾ëŠ” ì¤‘...")
        
        # 1. FAISS ë²¡í„° DB í™•ì¸ ë° ìë™ ë™ê¸°í™”
        if not self._check_and_sync_vector_db():
            print("âŒ FAISS ë²¡í„° DBë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í´ë°± ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            return self._find_suitable_participants_fallback(analysis)
        
        # 2. FAISS ê²€ìƒ‰ì„ í•œ ë²ˆë§Œ ìˆ˜í–‰ (ê°€ì¥ ë¹„ìš©ì´ í° ì‘ì—…)
        print("ğŸ“Š FAISS ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")
        similar_projects = self.similarity_analyzer.search_similar_projects(
            self._build_search_query(analysis), k=30
        )
        print(f"âœ… FAISS ê²€ìƒ‰ ì™„ë£Œ: {len(similar_projects)}ê°œ í”„ë¡œì íŠ¸ ë°œê²¬")
        
        # 2. ì°¸ì—¬ìë³„ í”„ë¡œì íŠ¸ ë§¤í•‘ì„ ë¯¸ë¦¬ ìƒì„±
        participant_project_map = self._build_participant_project_map()
        
        # 3. ë§¤ì¹­ë˜ëŠ” ì°¸ì—¬ìì™€ ê´€ë ¨ í”„ë¡œì íŠ¸ë§Œ ì„ ë³„ (1ì°¨ í•„í„°ë§)
        matching_participants_with_projects = self._find_matching_participants_with_projects(
            similar_projects, participant_project_map
        )
        print(f"ğŸ¯ 1ì°¨ í•„í„°ë§ ì™„ë£Œ: {len(matching_participants_with_projects)}ëª…ì˜ í›„ë³´ ì°¸ì—¬ì ì„ ë³„")
        
        participant_scores = []
        
        # 4. ì„ ë³„ëœ ì°¸ì—¬ìë§Œ ìƒì„¸ ê³„ì‚°
        for i, (participant, matching_projects) in enumerate(matching_participants_with_projects.items()):
            print(f"ğŸ“ˆ ì°¸ì—¬ì {i+1}/{len(matching_participants_with_projects)}: {participant} ë¶„ì„ ì¤‘...")
            print(f"   ğŸ“‹ ë§¤ì¹­ëœ í”„ë¡œì íŠ¸: {len(matching_projects)}ê°œ")
            
            # ì í•©ë„ ê³„ì‚° (SimilarityAnalyzer ë‚´ë¶€ ìºì‹œ ì‚¬ìš©)
            suitability = self.similarity_analyzer.calculate_participant_suitability(
                analysis, participant, matching_projects
            )
            
            # ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ í¬í•¨
            if suitability['total_score'] >= 0.01:
                participant_scores.append(suitability)
        
        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        participant_scores.sort(key=lambda x: x['total_score'], reverse=True)
        
        print(f"âœ… ìµœì¢… ì¶”ì²œ: {len(participant_scores)}ëª…ì˜ ì í•©í•œ ì°¸ì—¬ì ì„ ë³„ ì™„ë£Œ")
        
        # ìƒìœ„ 10ëª…ë§Œ ì„ íƒ
        return participant_scores[:10]
    
    def _build_search_query(self, analysis: Dict[str, Any]) -> str:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        
        Args:
            analysis: ì‚¬ìš©ì ìš”ì²­ ë¶„ì„ ê²°ê³¼
            
        Returns:
            str: ê²€ìƒ‰ ì¿¼ë¦¬
        """
        query_parts = []
        req_caps = analysis.get('required_capabilities', '') or ''
        proj_char = analysis.get('project_characteristics', '') or ''
        tags = analysis.get('tags', []) or []
        
        if req_caps:
            query_parts.append(req_caps)
        if proj_char:
            query_parts.append(proj_char)
        if tags:
            query_parts.append(', '.join(tags))
        
        return '\n'.join(query_parts) if query_parts else ''
    
    def _build_participant_project_map(self) -> Dict[str, List[Dict[str, Any]]]:
        """
        ì°¸ì—¬ìë³„ í”„ë¡œì íŠ¸ ë§¤í•‘ì„ ë¯¸ë¦¬ ìƒì„±
        
        Returns:
            Dict[str, List[Dict[str, Any]]]: ì°¸ì—¬ìë³„ í”„ë¡œì íŠ¸ ëª©ë¡
        """
        all_participants = self.data_loader.get_all_participants()
        participant_project_map = {}
        
        for participant in all_participants:
            participant_projects = self.data_loader.get_projects_by_participant(participant)
            participant_project_map[participant] = participant_projects
        
        return participant_project_map
    
    def _find_matching_participants_with_projects(self, similar_projects: List[Tuple[Dict[str, Any], float]], 
                                                participant_project_map: Dict[str, List[Dict[str, Any]]]) -> Dict[str, List[Dict[str, Any]]]:
        """
        FAISS ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë§¤ì¹­ë˜ëŠ” ì°¸ì—¬ìë“¤ê³¼ ê´€ë ¨ í”„ë¡œì íŠ¸ë“¤ì„ ì„ ë³„
        
        Args:
            similar_projects: FAISS ê²€ìƒ‰ ê²°ê³¼
            participant_project_map: ì°¸ì—¬ìë³„ í”„ë¡œì íŠ¸ ë§¤í•‘
            
        Returns:
            Dict[str, List[Dict[str, Any]]]: ì°¸ì—¬ìë³„ ë§¤ì¹­ëœ í”„ë¡œì íŠ¸ ëª©ë¡
        """
        matching_participants_with_projects = {}
        
        # FAISS ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í”„ë¡œì íŠ¸ëª… ì¶”ì¶œ
        similar_project_names = set()
        for meta, score in similar_projects:
            project_name = meta.get('project_name', '')
            if project_name:
                similar_project_names.add(project_name)
        
        # ê° ì°¸ì—¬ìì— ëŒ€í•´ ë§¤ì¹­ëœ í”„ë¡œì íŠ¸ë§Œ ì„ ë³„
        for participant, all_projects in participant_project_map.items():
            matching_projects = []
            for project in all_projects:
                project_name = project.get('í”„ë¡œì íŠ¸ëª…', '')
                if project_name in similar_project_names:
                    matching_projects.append(project)
            
            # ë§¤ì¹­ëœ í”„ë¡œì íŠ¸ê°€ ìˆëŠ” ì°¸ì—¬ìë§Œ í¬í•¨
            if matching_projects:
                matching_participants_with_projects[participant] = matching_projects
        
        return matching_participants_with_projects
    
    def _check_and_sync_vector_db(self) -> bool:
        """
        FAISS ë²¡í„° DBê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ë™ê¸°í™”ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Returns:
            bool: ë²¡í„° DBê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ True, ì•„ë‹ˆë©´ False
        """
        # SimilarityAnalyzerì˜ ë²¡í„° DB ìƒíƒœ í™•ì¸
        if hasattr(self.similarity_analyzer, '_vector_store') and self.similarity_analyzer._vector_store is not None:
            return True
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        faiss_path = os.path.join(VECTOR_DB_DIR, f"{VECTOR_COLLECTION_NAME}.faiss")
        metadata_path = os.path.join(VECTOR_DB_DIR, f"{VECTOR_COLLECTION_NAME}.pkl")
        
        if os.path.exists(faiss_path) and os.path.exists(metadata_path):
            # íŒŒì¼ì´ ìˆìœ¼ë©´ SimilarityAnalyzerì—ì„œ ë¡œë“œ ì‹œë„
            try:
                if hasattr(self.similarity_analyzer, '_load_faiss_index'):
                    self.similarity_analyzer._load_faiss_index()
                    return hasattr(self.similarity_analyzer, '_vector_store') and self.similarity_analyzer._vector_store is not None
                return False
            except Exception as e:
                print(f"âš ï¸ ê¸°ì¡´ ë²¡í„° DB ë¡œë“œ ì‹¤íŒ¨: {e}")
                return False
        else:
            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ ë™ê¸°í™” ì‹¤í–‰
            print("ğŸ”„ FAISS ë²¡í„° DBê°€ ì—†ìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ë™ê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
            try:
                if hasattr(self.similarity_analyzer, 'sync_vector_db'):
                    doc_count = self.similarity_analyzer.sync_vector_db()
                    if doc_count > 0:
                        print(f"âœ… ë²¡í„° DB ë™ê¸°í™” ì™„ë£Œ: {doc_count}ê°œ ë¬¸ì„œ ì €ì¥")
                        return True
                    else:
                        print("âŒ ë²¡í„° DB ë™ê¸°í™” ì‹¤íŒ¨")
                        return False
                return False
            except Exception as e:
                print(f"âŒ ë²¡í„° DB ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                return False
    
    def _find_suitable_participants_fallback(self, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        FAISSë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì„ ë•Œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì°¸ì—¬ìë¥¼ ì°¾ëŠ” í´ë°± ë©”ì„œë“œ
        
        Args:
            analysis: ì‚¬ìš©ì ìš”ì²­ ë¶„ì„ ê²°ê³¼
            
        Returns:
            List[Dict[str, Any]]: ì„ ë³„ëœ ì°¸ì—¬ì ëª©ë¡
        """
        print("ğŸ”„ í´ë°± ë°©ì‹ìœ¼ë¡œ ì°¸ì—¬ì ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤...")
        
        all_participants = self.data_loader.get_all_participants()
        participant_scores = []
        
        # ëª¨ë“  ì°¸ì—¬ìì— ëŒ€í•´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ê³„ì‚°
        for i, participant in enumerate(all_participants):
            print(f"ğŸ“ˆ ì°¸ì—¬ì {i+1}/{len(all_participants)}: {participant} ë¶„ì„ ì¤‘...")
            
            # ì°¸ì—¬ìì˜ í”„ë¡œì íŠ¸ë“¤ ê°€ì ¸ì˜¤ê¸°
            participant_projects = self.data_loader.get_projects_by_participant(participant)
            
            # ì í•©ë„ ê³„ì‚° (í´ë°± ë°©ì‹)
            suitability = self.similarity_analyzer._calculate_participant_suitability_fallback(
                analysis, participant, participant_projects
            )
            
            # ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ í¬í•¨
            if suitability['total_score'] >= 0.01:
                participant_scores.append(suitability)
        
        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        participant_scores.sort(key=lambda x: x['total_score'], reverse=True)
        
        print(f"âœ… í´ë°± ë°©ì‹ ì™„ë£Œ: {len(participant_scores)}ëª…ì˜ ì í•©í•œ ì°¸ì—¬ì ì„ ë³„")
        
        # ìƒìœ„ 10ëª…ë§Œ ì„ íƒ
        return participant_scores[:10]

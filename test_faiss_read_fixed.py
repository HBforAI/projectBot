#!/usr/bin/env python3
"""
FAISS ì €ì¥ëœ ë°ì´í„° ì½ê¸° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (ìˆ˜ì •ëœ ë²„ì „)
=================================================

ì‹¤ì œ ì €ì¥ëœ FAISS íŒŒì¼ì„ ì˜¬ë°”ë¥´ê²Œ ì½ì–´ì˜¤ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""

import os
import sys
import pickle
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

def test_faiss_data_reading_fixed():
    """ì‹¤ì œ ì €ì¥ëœ FAISS ë°ì´í„°ë¥¼ ì½ì–´ì˜¤ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."""
    print("ğŸ” FAISS ì €ì¥ëœ ë°ì´í„° ì½ê¸° í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ ë²„ì „)")
    print("=" * 60)
    
    try:
        from langchain_community.vectorstores import FAISS
        from langchain_openai import OpenAIEmbeddings
        from src.core.config import VECTOR_DB_DIR
        
        print(f"ğŸ“‚ ë²¡í„° DB ë””ë ‰í† ë¦¬: {VECTOR_DB_DIR}")
        
        # ì‹¤ì œ ì €ì¥ëœ íŒŒì¼ í™•ì¸
        faiss_path = os.path.join(VECTOR_DB_DIR, "index.faiss")
        pkl_path = os.path.join(VECTOR_DB_DIR, "index.pkl")
        
        print(f"ğŸ“ FAISS íŒŒì¼: {faiss_path}")
        print(f"ğŸ“ PKL íŒŒì¼: {pkl_path}")
        
        if os.path.exists(faiss_path) and os.path.exists(pkl_path):
            print("âœ… ì €ì¥ëœ íŒŒì¼ë“¤ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
            
            # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
            
            # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
            print("ğŸ”„ FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘...")
            vector_store = FAISS.load_local(
                VECTOR_DB_DIR, 
                embeddings,
                allow_dangerous_deserialization=True
            )
            print("âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì„±ê³µ")
            
            # ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
            print("\nğŸ” ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
            results = vector_store.similarity_search_with_score("AI í”„ë¡œì íŠ¸", k=5)
            print(f"   ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
            
            for i, (doc, score) in enumerate(results):
                print(f"\n   {i+1}. ê±°ë¦¬ ì ìˆ˜: {score:.4f}")
                print(f"      ë‚´ìš©: {doc.page_content[:100]}...")
                print(f"      ë©”íƒ€ë°ì´í„°: {doc.metadata}")
            
            # ì¸ë±ìŠ¤ ì •ë³´ í™•ì¸
            print(f"\nğŸ“Š ì¸ë±ìŠ¤ ì •ë³´:")
            print(f"   ì´ ë²¡í„° ìˆ˜: {vector_store.index.ntotal}")
            print(f"   ë²¡í„° ì°¨ì›: {vector_store.index.d}")
            
        else:
            print("âŒ ì €ì¥ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            print(f"   FAISS íŒŒì¼ ì¡´ì¬: {os.path.exists(faiss_path)}")
            print(f"   PKL íŒŒì¼ ì¡´ì¬: {os.path.exists(pkl_path)}")
            
    except Exception as e:
        print(f"âŒ FAISS ì½ê¸° ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

def test_metadata_reading():
    """ë©”íƒ€ë°ì´í„°ë§Œ ì½ì–´ì˜¤ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."""
    print("\n" + "=" * 60)
    print("ğŸ“‹ ë©”íƒ€ë°ì´í„° ì½ê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    try:
        from src.core.config import VECTOR_DB_DIR
        
        pkl_path = os.path.join(VECTOR_DB_DIR, "index.pkl")
        
        if os.path.exists(pkl_path):
            print(f"ğŸ“ ë©”íƒ€ë°ì´í„° íŒŒì¼: {pkl_path}")
            
            with open(pkl_path, 'rb') as f:
                metadata = pickle.load(f)
            
            print(f"âœ… ë©”íƒ€ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(metadata)}ê°œ í•­ëª©")
            
            # ë©”íƒ€ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥
            print("\nğŸ“‹ ë©”íƒ€ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
            for i, meta in enumerate(metadata[:3]):
                print(f"\n   {i+1}. í”„ë¡œì íŠ¸ëª…: {meta.get('project_name', 'Unknown')}")
                print(f"      ê¸°ê°„: {meta.get('period', 'Unknown')}")
                print(f"      íƒœê·¸: {meta.get('tags', [])}")
                print(f"      ì°¸ì—¬ì: {meta.get('participants', [])}")
                print(f"      í”„ë¡œì íŠ¸ ID: {meta.get('project_id', 'Unknown')}")
        else:
            print(f"âŒ ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pkl_path}")
            
    except Exception as e:
        print(f"âŒ ë©”íƒ€ë°ì´í„° ì½ê¸° ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

def show_usage_examples():
    """ì‹¤ì œ ì‚¬ìš© ì˜ˆì œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤."""
    print("\n" + "=" * 60)
    print("ğŸ“š FAISS ë°ì´í„° ì½ê¸° ì‹¤ì œ ì‚¬ìš©ë²•")
    print("=" * 60)
    
    print("""
ğŸ”§ ë°©ë²• 1: SimilarityAnalyzer ì‚¬ìš© (ê°€ì¥ ê°„ë‹¨)
--------------------------------------------
from src.core.similarity_analyzer import SimilarityAnalyzer

analyzer = SimilarityAnalyzer()
results = analyzer.search_similar_projects("AI í”„ë¡œì íŠ¸", k=5)

for meta, score in results:
    print(f"í”„ë¡œì íŠ¸: {meta['project_name']}, ì ìˆ˜: {score:.4f}")

ğŸ”§ ë°©ë²• 2: ì§ì ‘ FAISS ë¡œë“œ (ê³ ê¸‰ ì‚¬ìš©)
------------------------------------
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# FAISS ì¸ë±ìŠ¤ ë¡œë“œ
vector_store = FAISS.load_local(
    "D:/vector_store", 
    embeddings,
    allow_dangerous_deserialization=True
)

# ê²€ìƒ‰ ì‹¤í–‰
results = vector_store.similarity_search_with_score("ê²€ìƒ‰ì–´", k=5)
for doc, score in results:
    print(f"ë‚´ìš©: {doc.page_content}")
    print(f"ë©”íƒ€ë°ì´í„°: {doc.metadata}")
    print(f"ê±°ë¦¬: {score}")

ğŸ”§ ë°©ë²• 3: ë©”íƒ€ë°ì´í„°ë§Œ ì½ê¸°
--------------------------
import pickle

with open("D:/vector_store/index.pkl", 'rb') as f:
    metadata = pickle.load(f)

print(f"ì´ {len(metadata)}ê°œì˜ í”„ë¡œì íŠ¸ ë°ì´í„°")
for meta in metadata:
    print(f"í”„ë¡œì íŠ¸: {meta['project_name']}")
    print(f"íƒœê·¸: {meta['tags']}")
    """)

if __name__ == "__main__":
    test_faiss_data_reading_fixed()
    test_metadata_reading()
    show_usage_examples()
